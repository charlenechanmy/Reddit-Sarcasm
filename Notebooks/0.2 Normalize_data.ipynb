{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51heZnmO_JQe",
    "outputId": "f28f2f25-8710-41f3-a446-5d28324d290c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.11)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "import stat\n",
    "from scipy.stats import pointbiserialr, pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import seaborn as sns\n",
    "\n",
    "#for text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "import gensim\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "!pip install pickle5\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iYrzs5Q_XNH"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmIr2qeO_NJN"
   },
   "outputs": [],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "id = '1Hqe-jJ-97wuX1PpI9dTKW16bsE2yh-Oi'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('final_test_data')  \n",
    "# Dataset is now stored in a Pandas Dataframe\n",
    "\n",
    "#pip install --upgrade pandas==1.3.4\n",
    "\n",
    "with open(\"final_test_data\", \"rb\") as fh:\n",
    "  test_data = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZyronr1CAuk"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.rename(columns={'dirty_cosine_similarity':'cosine_similarity_dirty_comments', 'clean_cosine_similarity':'cosine_similarity_clean_comments', 'sentiment':'comment_sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "id": "_KXXGq1oFwly",
    "outputId": "9f9d0f91-c3d1-4df7-9686-6595bce47ed4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>lemmatized_parent_comment</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>clean_parent_comment</th>\n",
       "      <th>lemmatized_clean_comment</th>\n",
       "      <th>lemmatized_clean_parent_comment</th>\n",
       "      <th>vectorized_comment</th>\n",
       "      <th>vectorized_clean_comment</th>\n",
       "      <th>vectorized_parent_comment</th>\n",
       "      <th>vectorized_clean_parent_comment</th>\n",
       "      <th>cosine_similarity_dirty_comments</th>\n",
       "      <th>cosine_similarity_clean_comments</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>has_repeated</th>\n",
       "      <th>exclaim_count</th>\n",
       "      <th>qns_mark_count</th>\n",
       "      <th>ellipses_mark_count</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>laughter_words_count</th>\n",
       "      <th>capitalized_word_count</th>\n",
       "      <th>partial_capital_word_count</th>\n",
       "      <th>emoticon_count</th>\n",
       "      <th>comment_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>794682</th>\n",
       "      <td>1</td>\n",
       "      <td>Racist comments are really rare on the internet so it's clearly the readers bias and not the rat...</td>\n",
       "      <td>Targash</td>\n",
       "      <td>news</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06</td>\n",
       "      <td>11/6/14 16:02</td>\n",
       "      <td>perhaps it is your bias dear redditor, and none of my own.</td>\n",
       "      <td>Racist comment really rare internet 's clearly reader bias rate occurrence one encounter racism ...</td>\n",
       "      <td>perhaps bias dear redditor , none .</td>\n",
       "      <td>Racist comments are really rare on the internet so its clearly the readers bias and not the rate...</td>\n",
       "      <td>perhaps it is your bias dear redditor and none of my own</td>\n",
       "      <td>Racist comment really rare internet clearly reader bias rate occurrence one encounter racism onl...</td>\n",
       "      <td>perhaps bias dear redditor none</td>\n",
       "      <td>[-0.2260461, -0.5411476, -0.5956079, 1.6732603, -0.35423955, -0.28117514, 1.0684463, 0.13423854,...</td>\n",
       "      <td>[-0.5515428, -0.59989977, 0.069325216, 1.5927559, -0.52806437, -0.07231382, 0.7368921, 0.7780658...</td>\n",
       "      <td>[-0.24906166, -0.65218884, 0.12795807, 0.646011, -0.11237952, 1.1585653, -0.18005028, -0.1678803...</td>\n",
       "      <td>[-0.33440658, -0.508268, 0.3577558, 0.4706608, 0.048984274, 1.179587, -0.04562621, -0.43975627, ...</td>\n",
       "      <td>0.250085</td>\n",
       "      <td>0.188576</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003517</th>\n",
       "      <td>0</td>\n",
       "      <td>yes, if good taste is what a cock doodle should do, then let a cock a doodle do.</td>\n",
       "      <td>superfusion1</td>\n",
       "      <td>sex</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01</td>\n",
       "      <td>19/1/11 15:32</td>\n",
       "      <td>That's the most tasteful video I have ever seen of a cock doodle.</td>\n",
       "      <td>yes , good taste cock doodle , let cock doodle .</td>\n",
       "      <td>That 's tasteful video I ever see cock doodle .</td>\n",
       "      <td>yes if good taste is what a cock doodle should do then let a cock a doodle do</td>\n",
       "      <td>Thats the most tasteful video I have ever seen of a cock doodle</td>\n",
       "      <td>yes good taste cock doodle let cock doodle</td>\n",
       "      <td>Thats tasteful video I ever see cock doodle</td>\n",
       "      <td>[-0.7737616, 0.4774656, 0.13742262, 0.18524809, -0.7151735, -0.11188578, 0.75100416, 0.35352728,...</td>\n",
       "      <td>[-0.76534796, 0.46344534, -0.03482504, -0.16052239, -0.7406304, 0.19035932, 0.670916, 0.35256463...</td>\n",
       "      <td>[-0.19669841, 0.023759527, 0.39963058, -0.104647115, -0.15868066, -0.20109259, -0.1438785, -0.20...</td>\n",
       "      <td>[-0.32654247, 0.2684772, 0.13918118, 0.002365145, -0.12061546, -0.17676899, -0.4078152, -0.27219...</td>\n",
       "      <td>0.249204</td>\n",
       "      <td>0.183911</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526207</th>\n",
       "      <td>1</td>\n",
       "      <td>Totally not photoshopped...</td>\n",
       "      <td>RB30DETT</td>\n",
       "      <td>funny</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12</td>\n",
       "      <td>11/12/15 17:29</td>\n",
       "      <td>London Underground</td>\n",
       "      <td>Totally photoshopped ...</td>\n",
       "      <td>London Underground</td>\n",
       "      <td>Totally not photoshopped</td>\n",
       "      <td>London Underground</td>\n",
       "      <td>Totally photoshopped</td>\n",
       "      <td>London Underground</td>\n",
       "      <td>[-0.14899243, -0.19366069, -0.20084605, 0.6875266, -0.20740944, 0.04641313, -0.015980119, -0.109...</td>\n",
       "      <td>[-0.11780262, -0.2061242, 0.010147771, 0.5353635, -0.105101734, 0.22466993, -0.017185103, -0.176...</td>\n",
       "      <td>[0.20910913, -0.055749796, 0.017575901, 0.48273495, -0.31094885, -0.11349381, 0.12859, 0.0609374...</td>\n",
       "      <td>[0.11732921, -0.14933924, 0.042169612, 0.49933022, -0.33947077, -0.084573105, 0.21897213, 0.0413...</td>\n",
       "      <td>0.760832</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169751</th>\n",
       "      <td>1</td>\n",
       "      <td>No, there's too much sexism in those industries and that makes it dangerous for women to join tr...</td>\n",
       "      <td>randomcombination102</td>\n",
       "      <td>TumblrInAction</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>18/12/16 2:17</td>\n",
       "      <td>Yeah, it's much easier to bitch about male privilege on the internet than learn a skilled trade</td>\n",
       "      <td>No , 's much sexism industry make dangerous woman join trade .</td>\n",
       "      <td>Yeah , 's much easy bitch male privilege internet learn skilled trade</td>\n",
       "      <td>No theres too much sexism in those industries and that makes it dangerous for women to join trades</td>\n",
       "      <td>Yeah its much easier to bitch about male privilege on the internet than learn a skilled trade</td>\n",
       "      <td>No there much sexism industry make dangerous woman join trade</td>\n",
       "      <td>Yeah much easy bitch male privilege internet learn skilled trade</td>\n",
       "      <td>[0.24865268, 0.7403738, 0.05449423, 0.81168157, -0.34635407, -0.21447319, -0.08545318, 0.5601065...</td>\n",
       "      <td>[0.31113982, 1.0847201, 0.07776833, 0.32138768, -0.4051754, -0.29240224, 0.35852677, 0.5766803, ...</td>\n",
       "      <td>[-0.6251248, -0.3786881, 0.0020529833, 1.2659732, -0.98284924, -0.47228277, 0.003996672, -0.5188...</td>\n",
       "      <td>[-0.52135706, -0.47163898, -0.053898532, 1.2260158, -0.94824064, -0.17594601, 0.30455595, -0.515...</td>\n",
       "      <td>0.222351</td>\n",
       "      <td>0.213574</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585774</th>\n",
       "      <td>0</td>\n",
       "      <td>Maybe they should take a leaf from the lending industry's playbook and offer 'typical' odds, the...</td>\n",
       "      <td>MemorableYetUnique</td>\n",
       "      <td>unitedkingdom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>19/10/15 20:15</td>\n",
       "      <td>It's because they specifically want to offer loss-making (to the bookie) bets to gain customers ...</td>\n",
       "      <td>Maybe take leaf lending industry 's playbook offer 'typical ' odds , way lender offer 'typical A...</td>\n",
       "      <td>It 's specifically want offer loss-making ( bookie ) bet gain customer know 'll get back 're hoo...</td>\n",
       "      <td>Maybe they should take a leaf from the lending industrys playbook and offer typical odds the way...</td>\n",
       "      <td>Its because they specifically want to offer lossmaking to the bookie bets to gain customers know...</td>\n",
       "      <td>Maybe take leaf lending industry playbook offer typical odds way lender offer typical APRs</td>\n",
       "      <td>Its specifically want offer lossmaking bookie bet gain customer know theyll get back theyre hook...</td>\n",
       "      <td>[0.022282721, 0.008266672, 0.74342155, 0.8594179, -1.1842369, 0.43431255, -0.605785, 1.4565908, ...</td>\n",
       "      <td>[0.8069845, 0.17959124, 0.5259561, 1.3175151, -1.3157947, 0.70151997, -0.11074356, 1.3665153, -1...</td>\n",
       "      <td>[-1.6010864, 1.8231604, -0.28390932, 0.62163574, -0.9412608, 1.695118, 0.75770545, 1.2171009, -2...</td>\n",
       "      <td>[-2.014457, 2.110243, -0.8449971, 1.1744075, 0.8436455, 1.8871673, 0.52350026, 0.53696537, -4.27...</td>\n",
       "      <td>0.192439</td>\n",
       "      <td>0.108372</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  ... comment_sentiment\n",
       "794682      1  ...               neg\n",
       "1003517     0  ...               pos\n",
       "526207      1  ...               neu\n",
       "169751      1  ...               neg\n",
       "585774      0  ...               neu\n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-97T8V7bCRua",
    "outputId": "1748dd84-2dad-4536-9225-dd510972cdd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202166, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNoPJJ_UCqcD",
    "outputId": "f7f4038a-c23f-46d6-d15e-bf90b4150545"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'comment', 'author', 'subreddit', 'score', 'ups', 'downs',\n",
       "       'date', 'created_utc', 'parent_comment', 'lemmatized_comment',\n",
       "       'lemmatized_parent_comment', 'clean_comment', 'clean_parent_comment',\n",
       "       'lemmatized_clean_comment', 'lemmatized_clean_parent_comment',\n",
       "       'vectorized_comment', 'vectorized_clean_comment',\n",
       "       'vectorized_parent_comment', 'vectorized_clean_parent_comment',\n",
       "       'cosine_similarity_dirty_comments', 'cosine_similarity_clean_comments',\n",
       "       'word_count', 'punctuation_count', 'has_repeated', 'exclaim_count',\n",
       "       'qns_mark_count', 'ellipses_mark_count', 'interjection_count',\n",
       "       'laughter_words_count', 'capitalized_word_count',\n",
       "       'partial_capital_word_count', 'emoticon_count', 'comment_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LPD5NzV_cft"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6sO_Z0YAODT"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.reset_index()\n",
    "\n",
    "test_data_to_normalize = test_data.loc[:,['word_count','punctuation_count','has_repeated','exclaim_count','qns_mark_count','ellipses_mark_count','interjection_count','laughter_words_count','capitalized_word_count','partial_capital_word_count','emoticon_count','cosine_similarity_dirty_comments','cosine_similarity_clean_comments']]\n",
    "norm_test_data_arr = scaler.fit_transform(test_data_to_normalize)\n",
    "test_norm_df = pd.DataFrame(norm_test_data_arr)\n",
    "\n",
    "test_norm_df.columns = ['word_count','punctuation_count','has_repeated','exclaim_count','qns_mark_count','ellipses_mark_count','interjection_count','laughter_words_count','capitalized_word_count','partial_capital_word_count','emoticon_count','cosine_similarity_dirty_comments','cosine_similarity_clean_comments']\n",
    "\n",
    "test_data.word_count = test_norm_df.word_count\n",
    "test_data.punctuation_count = test_norm_df.punctuation_count\n",
    "test_data.has_repeated = test_norm_df.has_repeated\n",
    "test_data.exclaim_count = test_norm_df.exclaim_count\n",
    "test_data.qns_mark_count = test_norm_df.qns_mark_count\n",
    "test_data.ellipses_mark_count = test_norm_df.ellipses_mark_count\n",
    "test_data.interjection_count = test_norm_df.interjection_count\n",
    "test_data.laughter_words_count = test_norm_df.laughter_words_count\n",
    "test_data.capitalized_word_count = test_norm_df.capitalized_word_count\n",
    "test_data.partial_capital_word_count = test_norm_df.partial_capital_word_count\n",
    "test_data.emoticon_count = test_norm_df.emoticon_count\n",
    "test_data.cosine_similarity_dirty_comments = test_norm_df.cosine_similarity_dirty_comments\n",
    "test_data.cosine_similarity_clean_comments = test_norm_df.cosine_similarity_clean_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbzviGKTjWwA",
    "outputId": "0b5ab5e5-c0ff-4539-d5d3-1142666d30ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                               0\n",
       "label                               0\n",
       "comment                             0\n",
       "author                              0\n",
       "subreddit                           0\n",
       "score                               0\n",
       "ups                                 0\n",
       "downs                               0\n",
       "date                                0\n",
       "created_utc                         0\n",
       "parent_comment                      0\n",
       "lemmatized_comment                  0\n",
       "lemmatized_parent_comment           0\n",
       "clean_comment                       0\n",
       "clean_parent_comment                0\n",
       "lemmatized_clean_comment            0\n",
       "lemmatized_clean_parent_comment     0\n",
       "vectorized_comment                  0\n",
       "vectorized_clean_comment            0\n",
       "vectorized_parent_comment           0\n",
       "vectorized_clean_parent_comment     0\n",
       "cosine_similarity_dirty_comments    0\n",
       "cosine_similarity_clean_comments    0\n",
       "word_count                          0\n",
       "punctuation_count                   0\n",
       "has_repeated                        0\n",
       "exclaim_count                       0\n",
       "qns_mark_count                      0\n",
       "ellipses_mark_count                 0\n",
       "interjection_count                  0\n",
       "laughter_words_count                0\n",
       "capitalized_word_count              0\n",
       "partial_capital_word_count          0\n",
       "emoticon_count                      0\n",
       "comment_sentiment                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPbzDhf2jXYH"
   },
   "outputs": [],
   "source": [
    "test_data.to_pickle(\"./norm_test_data\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0.2 Normalize data",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
